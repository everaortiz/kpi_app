import csv
from io import StringIO
import sqlalchemy
from sqlalchemy import create_engine

def _get_connection(conn):
    try:
        return conn.connection
    except AttributeError:
        return sqlalchemy.engine.Connection(create_engine(conn))

def psql_insert_copy(table, conn, keys, data_iter):
    """
    Execute SQL statement inserting data in a PostgreSQL DB

    Parameters
    ----------
    table : pandas.io.sql.SQLTable
    conn : sqlalchemy.engine.url.URL, sqlalchemy.engine.Engine or sqlalchemy.engine.Connection
    keys : list of str
        Column names
    data_iter : Iterable that iterates the values to be inserted
    """
    # gets a DBAPI connection that can provide a cursor
    dbapi_conn = _get_connection(conn)
    with dbapi_conn.cursor() as cursor:
        s_buf = StringIO()
        writer = csv.writer(s_buf)
        writer.writerows(data_iter)
        s_buf.seek(0)

        columns = ', '.join(['"{}"'.format(k) for k in keys])
        if table.schema:
            table_name = '{}.{}'.format(table.schema, table.name)
        else:
            table_name = table.name

        sql = 'COPY {} ({}) FROM STDIN WITH CSV'.format(
            table_name, columns)
        cursor.copy_expert(sql=sql, file=s_buf)

def mysql_upsert(table, conn, keys, data_iter):
    """
    Function to insert or update, in case rows already in, data to a MySQL table.
    It has to be used as the method parameter in the `pandas.DataFrame.to_sql()` method
    
    Parameters
    ----------
    table : pandas.io.sql.SQLTable
    conn : sqlalchemy.engine.url.URL, sqlalchemy.engine.Engine or sqlalchemy.engine.Connection
    keys : list of str
        Column names
    data_iter : Iterable that iterates the values to be inserted
    """

    upsert = f"""
        REPLACE INTO {table.name} ({', '.join(keys)})
        VALUES ({','.join(['%s'] * len(keys))})
    """

    dbapi_conn = _get_connection(conn)
    with dbapi_conn.cursor() as cursor:
        for data in data_iter:
            cursor.execute(upsert, data)